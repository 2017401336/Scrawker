2020-10-02 14:52:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 13, in parse
    print(labels.text)
AttributeError: text
2020-10-02 14:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\spiders\__init__.py", line 90, in _parse
    return self.parse(response, **kwargs)
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 13, in parse
    print(labels.extract_first())
AttributeError: 'Selector' object has no attribute 'extract_first'
2020-10-02 15:02:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:02:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:02:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:03:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 25, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:04:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers)
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:34:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:35:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:35:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:36:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:36:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:37:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:39:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:39:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 23, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:40:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 25, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:42:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 24, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:43:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest> (referer: None)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 25, in parse
    yield scrapy.Request(l,callback=self.parse_sun_info,headers=headers,meta={'all_name':n})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 15:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:46:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:52:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:52:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:52:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:53:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:53:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:53:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:54:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 15:55:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = li.css('[class="state2"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:00:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:00:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:00:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:01:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:01:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:01:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:02:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:02:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:02:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['status'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ','').replace('\n','').replace('\t','')
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce(' ',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state2"]').extract_first(),re.S)[0].repalce('\t',''))
AttributeError: 'str' object has no attribute 'repalce'
2020-10-02 16:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = li.css('[class="state4"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','').replace('"','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = li.css('[class="state4"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','').replace('"','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = li.css('[class="state4"]').re_first(r'<span.*?>(.*?)</span>').repalce(' ','').replace('\n','').replace('\t','').replace('"','')
AttributeError: 'NoneType' object has no attribute 'repalce'
2020-10-02 16:07:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:07:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 48, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:07:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:08:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:08:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:08:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 56, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:09:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:09:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:09:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:10:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':{'a':1},'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 57, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':{'a':1},'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:10:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:10:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:11:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:11:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:11:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 59, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 59, in parse_sun_info
    yield scrapy.Request(next_url,callback=self.parse_sun_info,headers=headers,meta={'next_url':next_url,'all_name':all_name})
  File "D:\python\lib\site-packages\scrapy\http\request\__init__.py", line 39, in __init__
    self.headers = Headers(headers or {}, encoding=encoding)
  File "D:\python\lib\site-packages\scrapy\http\headers.py", line 11, in __init__
    super(Headers, self).__init__(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 20, in __init__
    self.update(seq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 56, in update
    super(CaselessDict, self).update(iseq)
  File "D:\python\lib\site-packages\scrapy\utils\datatypes.py", line 55, in <genexpr>
    iseq = ((self.normkey(k), self.normvalue(v)) for k, v in seq)
ValueError: not enough values to unpack (expected 2, got 1)
2020-10-02 16:13:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:13:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:13:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:14:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:15:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:15:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:15:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:20:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:20:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:20:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:23:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:23:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:23:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 42, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:24:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:28:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:28:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:28:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:32:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 43, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 51, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:32:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:32:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 44, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:33:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:33:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:33:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:34:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:34:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 45, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:37:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 52, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:38:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 53, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:39:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:39:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:39:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 53, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:40:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:40:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 55, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:40:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 54, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:41:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 55, in parse_sun_info
    print(re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t',''))
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:42:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 58, in parse_sun_info
    item['reponsetime'] = re.findall(r'<span.*?>(.*?)</span>',li.css('[class="state4"]').extract_first(),re.S)[0].replace(' ','').replace('\n','').replace('\t','')
  File "D:\python\lib\re.py", line 239, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2020-10-02 16:49:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:49:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:50:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:54:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:54:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:54:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 47, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 41, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 41, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2> (referer: http://wz.sun0769.com/political/index/politicsNewest)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 41, in parse_sun_info
    if '2' in all_name['next_url']:
KeyError: 'next_url'
2020-10-02 16:55:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 49, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:55:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:56:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 50, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:57:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=3&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=3)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:57:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=2&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=2)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 16:57:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://wz.sun0769.com/political/index/politicsNewest?id=1&page=2> (referer: http://wz.sun0769.com/political/index/politicsNewest?id=1)
Traceback (most recent call last):
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\utils\python.py", line 347, in __next__
    return next(self.data)
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\python\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\python\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\spiders\sun.py", line 46, in parse_sun_info
    item['category'] = all_name['all_name']['name']
KeyError: 'name'
2020-10-02 17:18:48 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://wz.sun0769.com/robots.txt>: Unsupported scheme: b''
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:18:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://wz.sun0769.com/political/index/politicsNewest>
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:24:11 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://wz.sun0769.com/robots.txt>: Unsupported scheme: b''
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:24:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://wz.sun0769.com/political/index/politicsNewest>
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\python\lib\site-packages\twisted\python\failure.py", line 512, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\python\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 55, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 76, in download_request
    return handler.download_request(request, spider)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 88, in download_request
    return agent.download_request(request)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 354, in download_request
    d = agent.request(method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\python\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 268, in request
    endpoint=self._getEndpoint(self._proxyURI),
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1721, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\python\lib\site-packages\twisted\web\client.py", line 1599, in endpointForURI
    raise SchemeNotSupported("Unsupported scheme: %r" % (uri.scheme,))
twisted.web.error.SchemeNotSupported: Unsupported scheme: b''
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 16:34:52',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '饭堂',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474994'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 15:29:44',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '南城金丰商业街城附近空气污染严重',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474992'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 12:34:47',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '古梅路机动车占道',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474989'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 10:31:51',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '1号线通车后，鸿福路站是否会更名',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474975'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 10:25:18',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '老板拖欠工资',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474974'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 10:19:52',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '石排利丰花园10月1日中秋国庆停电大半天',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474973'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 10:17:53',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '万江街道石美社区鸬鹚窝新基坊新基坊五巷6号继续顶风违法抢建',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474972'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 09:57:26',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '家里飞入棉絮！',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474971'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-02 09:00:47',
 'reponsetime': '等待回复：33天23小时31分',
 'status': '已受理',
 'title': '塘厦林村北一新村周边建楼施工噪音',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474969'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 23:17:37',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '厚街星汇公馆欺诈',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474968'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 21:56:27',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '联华花园城花园城风车广场路灯损坏',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474963'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 20:53:11',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '消防安全隐患',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474960'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 20:41:11',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '关于学生作业问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474959'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 20:35:39',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '厚街南环路君濠酒店和维也纳酒店十字路口只有三个红绿灯',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474958'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 20:16:48',
 'reponsetime': '等待回复：33天23小时17分',
 'status': '已受理',
 'title': '东莞塘厦华正学校',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474957'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:37 [sunpolicy.spiders.sun] WARNING: 当前分类问题反映,第2页
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-10-02 14:22:56',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '道路坑坑洼洼，影响安全!',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474991'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-10-02 11:30:01',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '从正对我家大门的树反映出来的问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474985'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-10-02 10:46:42',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '摩托车泛滥',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474976'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-10-01 22:17:21',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '能办理土地使用证吗？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474964'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-10-01 21:53:28',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '电子琴声，无法休息。',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474962'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-10-01 05:23:40',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '常平镇蔚蓝城邦55栋1单元旁边的工厂养鸡凌晨三点打鸣',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474924'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-30 14:48:27',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '麻湧鎮有違建部門不處理',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474892'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-30 11:23:09',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '关于厂房在镇街报建的合规性咨询',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474863'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-30 11:16:50',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '莞惠城际所谓加速，就是牺牲部分站点的利益换来的?',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474861'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-30 11:15:54',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '关于厂房在镇街报建的合规性咨询',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474860'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-30 08:55:19',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '莞惠城际停站问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474836'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-29 16:55:55',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '反映莞惠轻轨“6+2”优化停站变得更不便民的问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474800'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-29 15:38:00',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '9月26日起莞惠轻轨“6+2”优化停站变得更不便民的问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474789'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-29 13:22:51',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '垃圾桶正对商铺大门？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474777'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-29 02:23:22',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '楼下每晚都传异味！',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474732'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:39 [sunpolicy.spiders.sun] WARNING: 当前分类热线论坛,第2页
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-30 15:59:45',
 'reponsetime': '等待处理：33天6小时6分',
 'status': '待处理',
 'title': '关于打通长安建安路和虎门新安东路联接的建议',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474897'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-24 22:20:01',
 'reponsetime': '等待回复：32天22小时5分',
 'status': '已受理',
 'title': '关于莞樟路增设大朗行政中心公交站的建议',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474328'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-23 11:52:42',
 'reponsetime': '等待回复：31天17小时21分',
 'status': '已受理',
 'title': '黄江镇龙见田【梅塘烈士公园】路口 至 地铁【黄江中心站】1.7KM无过街红绿灯',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474152'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-22 16:19:05',
 'reponsetime': '处理用时：7天15小时46分',
 'status': '已回复',
 'title': '广深磁悬浮设置东莞蛤地站',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474068'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-22 11:59:14',
 'reponsetime': '等待处理：25天6小时6分',
 'status': '待处理',
 'title': '望牛墩中心小学路段位上下学时间水泥车多',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474029'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-21 18:03:02',
 'reponsetime': '等待回复：26天2小时0分',
 'status': '已受理',
 'title': '关于外国语学校扩建方案考虑学生家长接送停车问题的建议',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473953'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-19 23:11:49',
 'reponsetime': '等待回复：24天17小时16分',
 'status': '已受理',
 'title': '4号线北延开通在即，大概十月一号，请主管部门认真考虑这几万人的出行需求。',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473787'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-18 14:18:54',
 'reponsetime': '处理用时：2天18小时8分',
 'status': '已回复',
 'title': '古树的保护',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473646'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-18 11:07:23',
 'reponsetime': '等待回复：28天17小时7分',
 'status': '已受理',
 'title': '桥头镇龙船博街早上道路拥堵现象',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473610'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-17 15:55:51',
 'reponsetime': '等待处理：20天6小时6分',
 'status': '待处理',
 'title': 'S358省道与八达路交叉路口车道优化建议',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473530'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-16 22:25:48',
 'reponsetime': '等待回复：21天21小时21分',
 'status': '已受理',
 'title': '东莞4路公交终点站',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473440'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-16 14:49:14',
 'reponsetime': '等待处理：19天6小时6分',
 'status': '待处理',
 'title': '关于东江大道车辆通行问题的建议',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473375'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-15 10:20:03',
 'reponsetime': '等待回复：26天16小时40分',
 'status': '已受理',
 'title': '环城东路横塘立交辅道交通优化建议',
 'url': 'http://wz.sun0769.com/political/politics/index?id=473149'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-13 08:14:48',
 'reponsetime': '处理用时：4天6小时11分',
 'status': '已回复',
 'title': '还路于民',
 'url': 'http://wz.sun0769.com/political/politics/index?id=472882'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [scrapy.core.scraper] ERROR: Error processing {'category': '诤言良策',
 'querytime': '2020-09-11 12:43:19',
 'reponsetime': '处理用时：1天5小时54分',
 'status': '已回复',
 'title': '临时停车初次轻微违法口头警告或初次免罚',
 'url': 'http://wz.sun0769.com/political/politics/index?id=472692'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:43 [sunpolicy.spiders.sun] WARNING: 当前分类诤言良策,第2页
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 19:50:55',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '卓越蔚蓝城邦北门二正门口有人占道经营儿童娱乐',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474956'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 18:15:54',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '乱停',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474954'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 18:01:56',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '关于电动摩托车！',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474953'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 17:16:58',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '高埗镇上江城餐馆油烟扰民',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474952'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 15:25:00',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '万科第五城人行天桥',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474950'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 15:21:11',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '东莞市城市管理综合执法局南城分局涉嫌欺瞒群众，刁难群众，并为黑恶势力充当保护伞',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474949'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 14:31:13',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '军龄视同社保缴费年限咨询',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474948'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 13:10:38',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '厚街城管与赤岭天桥小贩配合得真好',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474943'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 12:53:43',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '去年中在邮政申请的专票退税，至今未处理',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474942'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 12:28:28',
 'reponsetime': '等待回复：33天23小时21分',
 'status': '已受理',
 'title': '水渠堵塞',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474937'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 12:22:15',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '长年垃圾堆放，固定占道经营',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474936'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 11:07:07',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '南城东骏豪对面苑鹏瑞天玥工地，通宵施工，附近住户根本无法入眠！',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474931'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 10:15:24',
 'reponsetime': '等待回复：33天17小时34分',
 'status': '已受理',
 'title': '塘厦工会关于2019初级会计培训退费问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474925'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 05:11:36',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '常平蔚蓝城邦55栋1单元旁边工厂养鸡半夜三点鸡叫',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474923'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'querytime': '2020-10-01 01:14:25',
 'reponsetime': '等待处理：34天6小时6分',
 'status': '待处理',
 'title': '沙田立沙新区旁边的高速入口车辆半夜喇叭声不断',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474922'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:47 [sunpolicy.spiders.sun] WARNING: 当前分类问题反映,第3页
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-28 20:05:37',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '道路坑坑洼洼，影响安全！',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474714'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-28 16:46:53',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '新报建法？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474698'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-28 16:18:35',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '请住建局不要言而无信，不要漠视本地居民生存权，尽快开放宅基地报建，已经9个月，忍无吾忍了！',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474694'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-28 14:28:10',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '急！事实证明，劳动维权困难重重，投诉总是被打击报复，无人过问保护。正义何在？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474670'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-28 10:49:58',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '禁建区和限建区是哪些地方？恢复报建具体时间',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474614'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-28 09:12:03',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '9月26日起莞惠轻轨“6+2”停站方式真的合适吗？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474600'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-28 00:05:10',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '关于近期莞惠城轨部分站台不停靠的问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474586'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-27 14:44:51',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '商铺打墙开窗，影响业主居家安全',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474543'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-27 11:41:30',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '石排艺境湾花园逾期交楼发展商拒绝支付逾期',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474528'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-27 09:43:06',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '关于增加莞惠轻轨增加晚上通勤功能的建议',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474516'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-26 21:01:36',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '什么时候能实行空置税？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474501'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-26 20:22:54',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '目前辞工扣除去年年终奖的投诉',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474498'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-26 18:56:47',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '奶粉问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474494'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-26 13:14:47',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '在京东买的电脑坏了，投诉全无门',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474482'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'querytime': '2020-09-26 09:30:02',
 'reponsetime': '',
 'status': '热线论坛',
 'title': 'ETC车宝退款',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474459'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 17:53:50 [sunpolicy.spiders.sun] WARNING: 当前分类热线论坛,第3页
2020-10-02 17:54:05 [sunpolicy.spiders.sun] WARNING: 当前分类热线论坛,第2页
2020-10-02 17:54:09 [sunpolicy.spiders.sun] WARNING: 当前分类诤言良策,第2页
2020-10-02 18:42:15 [sunpolicy.spiders.sun] WARNING: 当前分类问题反映,第2页
2020-10-02 18:42:46 [sunpolicy.spiders.sun] WARNING: 当前分类热线论坛,第2页
2020-10-02 18:42:49 [sunpolicy.spiders.sun] WARNING: 当前分类诤言良策,第2页
2020-10-02 18:42:52 [sunpolicy.spiders.sun] WARNING: 当前分类问题反映,第2页
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '常平镇蔚蓝城邦55栋1单元旁边的工厂养鸡凌晨三点打鸣，应该是东莞众博塑料公司，天天如此，严重影响蔚蓝城邦居民的休息，请问下现在工厂可以养鸡吗？这个工厂不光养鸡，本身工厂噪音就很大，现在还弄个鸡呜，希望有关部门管管，谢谢',
 'img_url_list': [],
 'querytime': '2020-10-01 05:23:40',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '常平镇蔚蓝城邦55栋1单元旁边的工厂养鸡凌晨三点打鸣',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474924'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '東莞市麻湧中心大橋旁邊，麻湧河旁，麻四工業區，有兩棟違建，在工業區上沒有辦理手續建起了商業樓，現在建到十多層，當地城管部門視而不見！包庇從容！請市城管局查處。',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/0930/mark_1601448485547494.jpg'],
 'querytime': '2020-09-30 14:48:27',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '麻湧鎮有違建部門不處理',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474892'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-30 11:23:09',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '关于厂房在镇街报建的合规性咨询',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474863'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '摩托车到处盛行，发动机声音每晚震耳欲聋，交警不闻不问，却一个劲的针对电动车！',
 'img_url_list': [],
 'querytime': '2020-10-02 10:46:42',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '摩托车泛滥',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474976'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '对于莞城旧街道的治理我已经不想说什么了，办事效率不高，进度慢，而且处理的不及时，后面有问题也不能提供服务。导致我们通常有事情也不知道找谁好。说一下事由：前段时间这边修路绿化，重新种植了树，但我家的大门正对着这一课树，没有人先问过，没有人考虑过这个问题。但对风水这种我们还是比较在意比较重要的。大门正对大树不仅仅会让人感觉不方便，而且在风水学中，大门正对大树也是有风水讲究的。大家都知道，树对着大门正中是不好的，开门见树风水上谓之树撞煞、顶喉煞。树撞煞影响本宅纳气，损财运。住宅是阴阳两气交汇的地方，从广义上来讲，凡是被树木、竹子等冲撞、阻挡，影响阳宅采气，就犯树撞煞。门窗乃阳宅气口，从狭义来讲，树撞煞专指在大门（或窗户）正前方有树木呈现，影响气口采气。所以，我希望有人可以解决一下这个问题。',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1002/mark_1601609394806254_750x.png'],
 'querytime': '2020-10-02 11:30:01',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '从正对我家大门的树反映出来的问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474985'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:55 [sunpolicy.spiders.sun] WARNING: 当前分类热线论坛,第3页
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-29 02:23:22',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '楼下每晚都传异味！',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474732'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '你好！我想了解一下我家里有个地皮大概是80平方左右，大概十年前村委分了一个地皮给我们（大约120平方已有证，已经造好房子了）因隔壁那个地皮（80平方）影响当年市容市貌就，当地村委会叫我们买下来那我们就买了下来盖了铁皮房.我想问一下现在那80平方能去办理土地使用证吗？或者能报建造房子吗？',
 'img_url_list': [],
 'querytime': '2020-10-01 22:17:21',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '能办理土地使用证吗？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474964'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '东莞市厚街镇厚街村前进小学南门口旁边这条路，到处都是图片这种坑坑洼洼，导致骑自行车或者电动车容易发生摔跤或者其他安全事故，另外有很多家长都是骑电动车接送学生的，很不安全，希望有关部门对这条路进行修复，附近居民反映这条路几十年都没有维护了，到处都是裸露的碎石路面。现在也是东莞创文复核阶段，希望这个路面可以尽快修好。这个之前投诉过一次，编号261383，居然没人处理。请核实！',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1002/mark_1601619705442706.jpg'],
 'querytime': '2020-10-02 14:22:56',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '道路坑坑洼洼，影响安全!',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474991'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '垃圾桶正对大门，为商铺考虑过吗？市政工程，应该是为民方便，而不是为民添堵！',
 'img_url_list': [],
 'querytime': '2020-09-29 13:22:51',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '垃圾桶正对商铺大门？',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474777'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '已经到了无法语言表达，只有三问万江领导。一问：社区工作人员和住村干部的工作方式，工作方法，工作责任。二问：这琴声到底有沒有方法消停，到底有没有方法令女住房詹某某沟通达成共识，还村民一片安居的环境。三问：如果这事万江政府及新和社区工作人员，无法解决这事，那我永远不投诉了，（这事投诉长达一年半了，加起来有五六次，还有意思吗？）',
 'img_url_list': [],
 'querytime': '2020-10-01 21:53:28',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '电子琴声，无法休息。',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474962'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': None,
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/0930/mark_1601435809318871_750x.jpg'],
 'querytime': '2020-09-30 11:16:50',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '莞惠城际所谓加速，就是牺牲部分站点的利益换来的?',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474861'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-29 15:38:00',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '9月26日起莞惠轻轨“6+2”优化停站变得更不便民的问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474789'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': '莞惠城际从9月26日调整停站方式后，作为市民造成极大影响，城际的初衷是便民的交通，为何要改为6+2的停站方式？作为东莞偏远地区的谢岗，本就公共交通工具少，不方便，但幸有莞惠城际轻轨方便市民日常出行之交通工具，但为何修改了停站方式？造成学生上学无车可坐，完全失去了城际轨道便民的意义。',
 'img_url_list': [],
 'querytime': '2020-09-30 08:55:19',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '莞惠城际停站问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474836'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-30 11:15:54',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '关于厂房在镇街报建的合规性咨询',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474860'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'content': '东莞第一中学高一英语国庆作业严重超标，影响学生的假期质量，学生很痛苦，每天都有英语作业，真的特别多特别多，救救孩子吧',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1001/mark_1601556071314172_750x.jpg'],
 'querytime': '2020-10-01 20:41:11',
 'reponsetime': '等待处理：34天5小时17分',
 'status': '待处理',
 'title': '关于学生作业问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474959'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '热线论坛',
 'content': None,
 'img_url_list': [],
 'querytime': '2020-09-29 16:55:55',
 'reponsetime': '',
 'status': '热线论坛',
 'title': '反映莞惠轻轨“6+2”优化停站变得更不便民的问题',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474800'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [scrapy.core.scraper] ERROR: Error processing {'category': '问题反映',
 'content': '厚街南环路君濠酒店和维也纳酒店十字路口只有三个红绿灯，明丰广场往新城88方向的红绿灯直接没有，超危险，过斑马线被夹在中间简直胆战心惊',
 'img_url_list': ['http://ugcuploadzdg.sun0769.com/1/2020/1001/mark_1601555728753535_750x.png',
                  'http://ugcuploadzdg.sun0769.com/1/2020/1001/mark_1601555734910488_750x.png'],
 'querytime': '2020-10-01 20:35:39',
 'reponsetime': '等待处理：34天5小时17分',
 'status': '待处理',
 'title': '厚街南环路君濠酒店和维也纳酒店十字路口只有三个红绿灯',
 'url': 'http://wz.sun0769.com/political/politics/index?id=474958'}
Traceback (most recent call last):
  File "D:\python\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python\lib\site-packages\scrapy\utils\defer.py", line 157, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\PyCharm 2018.3.5\sunpolicy\sunpolicy\pipelines.py", line 17, in process_item
    collection.insert(item)
  File "D:\python\lib\site-packages\pymongo\collection.py", line 3181, in insert
    return self._insert(doc_or_docs, not continue_on_error,
  File "D:\python\lib\site-packages\pymongo\collection.py", line 610, in _insert
    return self._insert_one(
  File "D:\python\lib\site-packages\pymongo\collection.py", line 564, in _insert_one
    doc['_id'] = ObjectId()
  File "D:\python\lib\site-packages\scrapy\item.py", line 99, in __setitem__
    raise KeyError("%s does not support field: %s" % (self.__class__.__name__, key))
KeyError: 'SunpolicyItem does not support field: _id'
2020-10-02 18:42:59 [sunpolicy.spiders.sun] WARNING: 当前分类问题反映,第3页
